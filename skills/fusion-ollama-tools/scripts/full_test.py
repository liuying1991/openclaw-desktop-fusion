#!/usr/bin/env python3
"""
å®Œæ•´æµ‹è¯•è„šæœ¬ - æµ‹è¯•Ollamaå·¥å…·è°ƒç”¨å’ŒOpenClawé›†æˆ

æµ‹è¯•å†…å®¹:
1. OllamaæœåŠ¡è¿æ¥
2. å·¥å…·å®šä¹‰åŠ è½½
3. å·¥å…·è°ƒç”¨è¯·æ±‚
4. å·¥å…·æ‰§è¡Œ
5. å®Œæ•´æµç¨‹éªŒè¯
"""

import sys
import os
import json

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from ollama_tools import (
    OllamaToolCaller, 
    OllamaConfig,
    test_connection,
    list_models
)
from tool_definitions import (
    get_all_tools_ollama_format,
    get_tools_by_category
)
from tool_executor import (
    MockToolExecutor,
    create_tool_registry
)


def print_header(title):
    print("\n" + "=" * 60)
    print(title)
    print("=" * 60)


def test_ollama_service():
    print_header("æµ‹è¯•1: OllamaæœåŠ¡çŠ¶æ€")
    
    if not test_connection():
        print("  âœ— OllamaæœåŠ¡æœªè¿è¡Œ")
        return None
    
    print("  âœ“ OllamaæœåŠ¡è¿è¡Œä¸­")
    
    models = list_models()
    print(f"\n  å¯ç”¨æ¨¡å‹ ({len(models)}ä¸ª):")
    for m in models:
        print(f"    â€¢ {m}")
    
    tool_models = [m for m in models if any(x in m.lower() for x in ['qwen', 'llama3', 'mistral', 'phi', 'glm'])]
    
    if tool_models:
        selected = tool_models[0]
        print(f"\n  é€‰æ‹©æ¨¡å‹: {selected}")
        return selected
    
    print("  âœ— æ²¡æœ‰æ”¯æŒå·¥å…·è°ƒç”¨çš„æ¨¡å‹")
    return None


def test_tool_definitions():
    print_header("æµ‹è¯•2: å·¥å…·å®šä¹‰åŠ è½½")
    
    tools = get_all_tools_ollama_format()
    print(f"  æ€»å·¥å…·æ•°é‡: {len(tools)}")
    
    categories = ["desktop", "screen", "clipboard", "window", "browser"]
    print("\n  æŒ‰ç±»åˆ«ç»Ÿè®¡:")
    for cat in categories:
        cat_tools = get_tools_by_category(cat)
        print(f"    â€¢ {cat}: {len(cat_tools)}ä¸ª")
    
    print("\n  ç¤ºä¾‹å·¥å…·å®šä¹‰:")
    sample = tools[0]
    print(f"    åç§°: {sample['function']['name']}")
    print(f"    æè¿°: {sample['function']['description'][:50]}...")
    
    return True


def test_tool_calling(model):
    print_header("æµ‹è¯•3: Ollamaå·¥å…·è°ƒç”¨")
    
    if not model:
        print("  âœ— è·³è¿‡: æ²¡æœ‰å¯ç”¨æ¨¡å‹")
        return False
    
    config = OllamaConfig(
        base_url="http://127.0.0.1:11434",
        model=model,
        timeout=60
    )
    caller = OllamaToolCaller(config)
    
    desktop_tools = [t.to_ollama_format() for t in get_tools_by_category("desktop")[:5]]
    
    test_cases = [
        "è¯·å‘Šè¯‰æˆ‘ä½ æœ‰å“ªäº›æ¡Œé¢æ§åˆ¶å·¥å…·",
        "è¯·å¸®æˆ‘è·å–å½“å‰é¼ æ ‡ä½ç½®",
        "è¯·å¸®æˆ‘ç‚¹å‡»å±å¹•åæ ‡(100, 200)"
    ]
    
    results = []
    for i, msg in enumerate(test_cases):
        print(f"\n  æµ‹è¯•ç”¨ä¾‹ {i+1}: {msg}")
        try:
            response = caller.chat_with_tools(
                user_message=msg,
                tools=desktop_tools
            )
            
            if "error" in response and response.get("error"):
                print(f"    âœ— è¯·æ±‚å¤±è´¥: {response.get('message')}")
                results.append(False)
                continue
            
            message = response.get("message", {})
            content = message.get("content", "")
            tool_calls = message.get("tool_calls", [])
            
            if content:
                print(f"    å“åº”å†…å®¹: {content[:100]}...")
            
            if tool_calls:
                print(f"    å·¥å…·è°ƒç”¨: {len(tool_calls)}ä¸ª")
                for tc in tool_calls:
                    func = tc.get("function", {})
                    print(f"      â†’ {func.get('name')}: {func.get('arguments')}")
            
            print("    âœ“ æµ‹è¯•é€šè¿‡")
            results.append(True)
            
        except Exception as e:
            print(f"    âœ— å¼‚å¸¸: {e}")
            results.append(False)
    
    return all(results)


def test_tool_execution():
    print_header("æµ‹è¯•4: å·¥å…·æ‰§è¡Œå™¨")
    
    registry = create_tool_registry()
    print(f"  å·¥å…·æ³¨å†Œè¡¨: {len(registry)}ä¸ªå·¥å…·")
    
    mock_executor = MockToolExecutor()
    
    test_tools = [
        ("desktop_position", {}),
        ("desktop_click", {"x": 100, "y": 200}),
        ("desktop_type", {"text": "Hello World"}),
    ]
    
    print("\n  æ¨¡æ‹Ÿæ‰§è¡Œæµ‹è¯•:")
    for tool_name, args in test_tools:
        if tool_name in registry:
            info = registry[tool_name]
            result = mock_executor.execute_tool(
                tool_name=tool_name,
                arguments=args,
                skill_path=info["skill_path"],
                skill_action=info["skill_action"]
            )
            status = "âœ“" if result.success else "âœ—"
            print(f"    {status} {tool_name}: {result.duration:.4f}s")
        else:
            print(f"    âœ— {tool_name}: æœªæ³¨å†Œ")
    
    return True


def test_full_workflow(model):
    print_header("æµ‹è¯•5: å®Œæ•´å·¥ä½œæµç¨‹")
    
    if not model:
        print("  âœ— è·³è¿‡: æ²¡æœ‰å¯ç”¨æ¨¡å‹")
        return False
    
    config = OllamaConfig(model=model)
    caller = OllamaToolCaller(config)
    
    tools = [t.to_ollama_format() for t in get_tools_by_category("desktop")[:3]]
    
    print("\n  å‘é€è¯·æ±‚: è¯·å¸®æˆ‘æˆªå±ä¿å­˜åˆ°/tmp/test.png")
    
    try:
        response = caller.chat_with_tools(
            user_message="è¯·å¸®æˆ‘æˆªå±ä¿å­˜åˆ°/tmp/test.png",
            tools=tools
        )
        
        message = response.get("message", {})
        tool_calls = message.get("tool_calls", [])
        content = message.get("content", "")
        
        if content:
            print(f"\n  æ¨¡å‹å“åº”: {content[:200]}...")
        
        if tool_calls:
            print(f"\n  æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {len(tool_calls)}ä¸ª")
            for tc in tool_calls:
                func = tc.get("function", {})
                print(f"    â†’ å·¥å…·: {func.get('name')}")
                print(f"    â†’ å‚æ•°: {func.get('arguments')}")
            print("\n  âœ“ å·¥å…·è°ƒç”¨è¯†åˆ«æˆåŠŸ!")
        else:
            print("\n  æ¨¡å‹æœªè°ƒç”¨å·¥å…·ï¼ˆå¯èƒ½ç›´æ¥å›ç­”ï¼‰")
        
        return True
        
    except Exception as e:
        print(f"\n  âœ— æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    print("\n" + "=" * 60)
    print("OpenClaw Ollamaå·¥å…·è°ƒç”¨ç³»ç»Ÿ - å®Œæ•´æµ‹è¯•")
    print("=" * 60)
    
    model = test_ollama_service()
    
    test_results = []
    
    test_results.append(("å·¥å…·å®šä¹‰", test_tool_definitions()))
    test_results.append(("å·¥å…·è°ƒç”¨", test_tool_calling(model)))
    test_results.append(("å·¥å…·æ‰§è¡Œ", test_tool_execution()))
    test_results.append(("å®Œæ•´æµç¨‹", test_full_workflow(model)))
    
    print_header("æµ‹è¯•ç»“æœæ±‡æ€»")
    
    passed = 0
    failed = 0
    for name, result in test_results:
        if result:
            print(f"  âœ“ {name}: é€šè¿‡")
            passed += 1
        else:
            print(f"  âœ— {name}: å¤±è´¥")
            failed += 1
    
    print(f"\n  æ€»è®¡: {passed}é€šè¿‡, {failed}å¤±è´¥")
    print("=" * 60)
    
    if failed == 0:
        print("\n  ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! Ollamaå·¥å…·è°ƒç”¨ç³»ç»Ÿå·¥ä½œæ­£å¸¸!")
    else:
        print("\n  âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
    
    return failed == 0


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
